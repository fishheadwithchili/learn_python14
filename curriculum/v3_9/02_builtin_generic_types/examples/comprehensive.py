"""
ç»¼åˆç¤ºä¾‹ï¼šæ•°æ®å¤„ç†ç®¡é“

åœºæ™¯ï¼šæ„å»ºä¸€ä¸ªå®Œæ•´çš„æ•°æ®å¤„ç†ç®¡é“ï¼ŒåŒ…æ‹¬æ•°æ®åŠ è½½ã€è½¬æ¢ã€éªŒè¯ã€
èšåˆå’Œå¯¼å‡ºï¼Œå±•ç¤ºå†…ç½®æ³›å‹ç±»å‹åœ¨å®é™…åº”ç”¨ä¸­çš„ç»¼åˆè¿ç”¨ã€‚
"""

from dataclasses import dataclass, field
from typing import TypeVar, Callable

T = TypeVar('T')

# ============= æ•°æ®æ¨¡å‹ =============

@dataclass
class Record:
    """æ•°æ®è®°å½•"""
    id: int
    category: str
    value: float
    tags: list[str]
    metadata: dict[str, str]
    
    def has_tag(self, tag: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«æ ‡ç­¾"""
        return tag in self.tags


@dataclass
class ProcessingStats:
    """å¤„ç†ç»Ÿè®¡"""
    total_records: int = 0
    processed: int = 0
    errors: int = 0
    warnings: list[str] = field(default_factory=list)
    
    def success_rate(self) -> float:
        """æˆåŠŸç‡"""
        return self.processed / self.total_records if self.total_records > 0 else 0.0


# ============= æ•°æ®ç®¡é“ =============

class DataPipeline:
    """æ•°æ®å¤„ç†ç®¡é“"""
    
    _data: list[Record]
    _filters: list[Callable[[Record], bool]]
    _transformers: list[Callable[[Record], Record]]
    _cache: dict[str, list[Record]]
    stats: ProcessingStats
    
    def __init__(self):
        self._data = []
        self._filters = []
        self._transformers = []
        self._cache = {}
        self.stats = ProcessingStats()
    
    def load(self, records: list[Record]) -> 'DataPipeline':
        """åŠ è½½æ•°æ®"""
        self._data = records
        self.stats.total_records = len(records)
        print(f"âœ… åŠ è½½äº† {len(records)} æ¡è®°å½•")
        return self
    
    def filter(self, predicate: Callable[[Record], bool]) -> 'DataPipeline':
        """æ·»åŠ è¿‡æ»¤å™¨"""
        self._filters.append(predicate)
        return self
    
    def transform(self, transformer: Callable[[Record], Record]) -> 'DataPipeline':
        """æ·»åŠ è½¬æ¢å™¨"""
        self._transformers.append(transformer)
        return self
    
    def execute(self) -> list[Record]:
        """æ‰§è¡Œç®¡é“"""
        result: list[Record] = self._data.copy()
        
        # åº”ç”¨è¿‡æ»¤å™¨
        for filter_func in self._filters:
            result = [r for r in result if filter_func(r)]
        
        # åº”ç”¨è½¬æ¢å™¨
        for transform_func in self._transformers:
            try:
                result = [transform_func(r) for r in result]
                self.stats.processed = len(result)
            except Exception as e:
                self.stats.errors += 1
                self.stats.warnings.append(f"è½¬æ¢é”™è¯¯: {e}")
        
        return result
    
    def group_by(self, key_func: Callable[[Record], str]) -> dict[str, list[Record]]:
        """æŒ‰é”®å‡½æ•°åˆ†ç»„"""
        result: dict[str, list[Record]] = {}
        
        for record in self._data:
            key = key_func(record)
            result.setdefault(key, []).append(record)
        
        return result
    
    def aggregate(
        self,
        group_key: Callable[[Record], str],
        agg_func: Callable[[list[Record]], float]
    ) -> dict[str, float]:
        """èšåˆæ•°æ®"""
        groups = self.group_by(group_key)
        return {key: agg_func(records) for key, records in groups.items()}
    
    def cache_result(self, key: str, data: list[Record]) -> None:
        """ç¼“å­˜ç»“æœ"""
        self._cache[key] = data
    
    def get_cache(self, key: str) -> list[Record] | None:
        """è·å–ç¼“å­˜"""
        return self._cache.get(key)


# ============= æ•°æ®éªŒè¯ =============

class DataValidator:
    """æ•°æ®éªŒè¯å™¨"""
    
    _rules: list[tuple[str, Callable[[Record], bool]]]
    
    def __init__(self):
        self._rules = []
    
    def add_rule(self, name: str, rule: Callable[[Record], bool]) -> 'DataValidator':
        """æ·»åŠ éªŒè¯è§„åˆ™"""
        self._rules.append((name, rule))
        return self
    
    def validate(self, records: list[Record]) -> dict[str, list[int]]:
        """éªŒè¯æ•°æ®ï¼Œè¿”å›æ¯ä¸ªè§„åˆ™çš„è¿è§„è®°å½•ID"""
        violations: dict[str, list[int]] = {}
        
        for name, rule in self._rules:
            violated_ids = [r.id for r in records if not rule(r)]
            if violated_ids:
                violations[name] = violated_ids
        
        return violations


# ============= è¾…åŠ©å‡½æ•° =============

def create_sample_data() -> list[Record]:
    """åˆ›å»ºç¤ºä¾‹æ•°æ®"""
    return [
        Record(1, "A", 100.0, ["important", "urgent"], {"source": "system1"}),
        Record(2, "B", 50.0, ["normal"], {"source": "system2"}),
        Record(3, "A", 150.0, ["important"], {"source": "system1"}),
        Record(4, "C", 75.0, ["urgent"], {"source": "system3"}),
        Record(5, "B", 200.0, ["important", "normal"], {"source": "system2"}),
        Record(6, "A", 25.0, ["normal"], {"source": "system1"}),
        Record(7, "C", 300.0, ["important", "urgent"], {"source": "system3"}),
    ]


# ============= ä¸»ç¨‹åº =============

def main():
    print("=" * 70)
    print("ç»¼åˆç¤ºä¾‹ï¼šæ•°æ®å¤„ç†ç®¡é“")
    print("=" * 70)
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    data = create_sample_data()
    
    # åœºæ™¯ 1ï¼šæ•°æ®åŠ è½½å’ŒåŸºæœ¬å¤„ç†
    print("\n[åœºæ™¯ 1] æ•°æ®åŠ è½½å’ŒåŸºæœ¬å¤„ç†\n")
    
    pipeline = DataPipeline()
    pipeline.load(data)
    
    print(f"æ•°æ®é¢„è§ˆï¼ˆå‰3æ¡ï¼‰:")
    for record in data[:3]:
        print(f"  - ID:{record.id}, ç±»åˆ«:{record.category}, å€¼:{record.value}, æ ‡ç­¾:{record.tags}")
    
    # åœºæ™¯ 2ï¼šè¿‡æ»¤å’Œè½¬æ¢
    print("\n[åœºæ™¯ 2] è¿‡æ»¤å’Œè½¬æ¢\n")
    
    # è¿‡æ»¤ï¼šåªä¿ç•™é‡è¦çš„è®°å½•
    filtered_pipeline = (
        DataPipeline()
        .load(data)
        .filter(lambda r: r.has_tag("important"))
        .filter(lambda r: r.value > 50)
    )
    
    filtered_data = filtered_pipeline.execute()
    print(f"è¿‡æ»¤åè®°å½•æ•°: {len(filtered_data)}")
    print(f"è¿‡æ»¤æ¡ä»¶: åŒ…å«'important'æ ‡ç­¾ ä¸” å€¼>50")
    
    for record in filtered_data:
        print(f"  - ID:{record.id}, å€¼:{record.value}")
    
    # åœºæ™¯ 3ï¼šæ•°æ®è½¬æ¢
    print("\n[åœºæ™¯ 3] æ•°æ®è½¬æ¢\n")
    
    # è½¬æ¢ï¼šå°†å€¼åŠ å€
    transformed_pipeline = (
        DataPipeline()
        .load(data)
        .transform(lambda r: Record(
            r.id, r.category, r.value * 2, r.tags, r.metadata
        ))
    )
    
    transformed_data = transformed_pipeline.execute()
    
    print("åŸå§‹å€¼ vs è½¬æ¢å:")
    for i in range(min(3, len(data))):
        print(f"  ID:{data[i].id} - åŸå§‹:{data[i].value:.1f}, è½¬æ¢å:{transformed_data[i].value:.1f}")
    
    # åœºæ™¯ 4ï¼šåˆ†ç»„å’Œèšåˆ
    print("\n[åœºæ™¯ 4] åˆ†ç»„å’Œèšåˆ\n")
    
    # æŒ‰ç±»åˆ«åˆ†ç»„
    pipeline_for_grouping = DataPipeline().load(data)
    groups = pipeline_for_grouping.group_by(lambda r: r.category)
    
    print("æŒ‰ç±»åˆ«åˆ†ç»„:")
    for category, records in groups.items():
        print(f"  ç±»åˆ« {category}: {len(records)} æ¡è®°å½•")
    
    # æŒ‰ç±»åˆ«èšåˆï¼ˆè®¡ç®—å¹³å‡å€¼ï¼‰
    avg_by_category = pipeline_for_grouping.aggregate(
        group_key=lambda r: r.category,
        agg_func=lambda records: sum(r.value for r in records) / len(records)
    )
    
    print("\næŒ‰ç±»åˆ«å¹³å‡å€¼:")
    for category, avg in avg_by_category.items():
        print(f"  ç±»åˆ« {category}: {avg:.2f}")
    
    # åœºæ™¯ 5ï¼šæ•°æ®éªŒè¯
    print("\n[åœºæ™¯ 5] æ•°æ®éªŒè¯\n")
    
    validator = (
        DataValidator()
        .add_rule("value_positive", lambda r: r.value > 0)
        .add_rule("category_valid", lambda r: r.category in ["A", "B", "C"])
        .add_rule("has_tags", lambda r: len(r.tags) > 0)
    )
    
    violations = validator.validate(data)
    
    if violations:
        print("å‘ç°éªŒè¯é”™è¯¯:")
        for rule, violated_ids in violations.items():
            print(f"  è§„åˆ™ '{rule}' è¿è§„: {violated_ids}")
    else:
        print("âœ… æ‰€æœ‰æ•°æ®éªŒè¯é€šè¿‡")
    
    # åœºæ™¯ 6ï¼šå¤æ‚æŸ¥è¯¢
    print("\n[åœºæ™¯ 6] å¤æ‚æŸ¥è¯¢ï¼ˆå¤šæ¡ä»¶è¿‡æ»¤ + æ’åºï¼‰\n")
    
    complex_query = (
        DataPipeline()
        .load(data)
        .filter(lambda r: r.category in ["A", "B"])
        .filter(lambda r: r.has_tag("important") or r.has_tag("urgent"))
    )
    
    query_result = complex_query.execute()
    # æ‰‹åŠ¨æ’åºï¼ˆæŒ‰å€¼é™åºï¼‰
    query_result_sorted = sorted(query_result, key=lambda r: r.value, reverse=True)
    
    print(f"æŸ¥è¯¢ç»“æœï¼ˆå‰3æ¡ï¼‰:")
    for record in query_result_sorted[:3]:
        print(f"  - ID:{record.id}, ç±»åˆ«:{record.category}, å€¼:{record.value}, æ ‡ç­¾:{record.tags}")
    
    # åœºæ™¯ 7ï¼šç»Ÿè®¡ä¿¡æ¯
    print("\n[åœºæ™¯ 7] å¤„ç†ç»Ÿè®¡\n")
    
    print(f"æ€»è®°å½•æ•°: {pipeline.stats.total_records}")
    print(f"æˆåŠŸç‡: {pipeline.stats.success_rate():.1%}")
    if pipeline.stats.warnings:
        print(f"è­¦å‘Š: {pipeline.stats.warnings}")
    
    # åœºæ™¯ 8ï¼šå¯¼å‡ºæ‘˜è¦
    print("\n[åœºæ™¯ 8] æ•°æ®æ‘˜è¦\n")
    
    summary: dict[str, dict[str, float | int]] = {}
    
    for category, records in groups.items():
        summary[category] = {
            "count": len(records),
            "total": sum(r.value for r in records),
            "average": sum(r.value for r in records) / len(records),
            "max": max(r.value for r in records),
            "min": min(r.value for r in records)
        }
    
    print("ç±»åˆ«æ‘˜è¦:")
    for category, stats in summary.items():
        print(f"  ç±»åˆ« {category}:")
        print(f"    æ•°é‡: {stats['count']}")
        print(f"    æ€»å’Œ: {stats['total']:.2f}")
        print(f"    å¹³å‡: {stats['average']:.2f}")
        print(f"    æœ€å¤§: {stats['max']:.2f}")
        print(f"    æœ€å°: {stats['min']:.2f}")
    
    # æ€»ç»“
    print("\n" + "=" * 70)
    print("ğŸ’¡ æ€»ç»“")
    print("=" * 70)
    print()
    print("å†…ç½®æ³›å‹ç±»å‹çš„ç»¼åˆåº”ç”¨ï¼š")
    print("  âœ… æ•°æ®æ¨¡å‹å®šä¹‰ï¼šdataclass + list[str], dict[str, str]")
    print("  âœ… ç®¡é“å¤„ç†ï¼šlist[Record], Callable[[Record], bool]")
    print("  âœ… åˆ†ç»„èšåˆï¼šdict[str, list[Record]]")
    print("  âœ… éªŒè¯è§„åˆ™ï¼šlist[tuple[str, Callable]]")
    print("  âœ… ç»Ÿè®¡æ‘˜è¦ï¼šdict[str, dict[str, float | int]]")
    print()
    print("é€‚ç”¨åœºæ™¯ï¼š")
    print("  â€¢ ETL æ•°æ®ç®¡é“")
    print("  â€¢ æ—¥å¿—åˆ†æç³»ç»Ÿ")
    print("  â€¢ æ•°æ®éªŒè¯æ¡†æ¶")
    print("  â€¢ æŠ¥è¡¨ç”Ÿæˆç³»ç»Ÿ")
    print("  â€¢ API æ•°æ®å¤„ç†")


if __name__ == "__main__":
    main()

