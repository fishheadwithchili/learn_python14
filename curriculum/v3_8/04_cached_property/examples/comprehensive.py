"""
cached_property å®æˆ˜ç¤ºä¾‹ï¼šMarkdown æ–‡æ¡£åˆ†æå™¨

ä¸šåŠ¡åœºæ™¯ï¼š
æ„å»ºä¸€ä¸ªæ–‡æ¡£åˆ†æå·¥å…·ï¼Œç”¨äºå¤„ç† Markdown æ–‡ä»¶ï¼š
1. è§£ææ–‡æ¡£å†…å®¹å’Œå…ƒæ•°æ®
2. ç”Ÿæˆæ–‡æ¡£æ‘˜è¦
3. ç»Ÿè®¡å­—æ•°å’Œé˜…è¯»æ—¶é—´
4. æå–æ ‡é¢˜å’Œé“¾æ¥

æ¼”ç¤º cached_property å¦‚ä½•é¿å…é‡å¤è®¡ç®—å’Œ I/O æ“ä½œã€‚

è¿è¡Œè¦æ±‚ï¼šPython >= 3.8
"""

from functools import cached_property
import re
import time
from typing import List, Dict

# ============ æ¨¡æ‹Ÿçš„ Markdown æ–‡æ¡£ ============

SAMPLE_MARKDOWN = """---
title: Python 3.8 æ–°ç‰¹æ€§æŒ‡å—
author: æŠ€æœ¯å›¢é˜Ÿ
date: 2024-01-15
tags: python, tutorial
---

# Python 3.8 æ–°ç‰¹æ€§æŒ‡å—

## ç®€ä»‹

Python 3.8 å¸¦æ¥äº†å¤šé¡¹é‡è¦æ”¹è¿›ï¼ŒåŒ…æ‹¬èµ‹å€¼è¡¨è¾¾å¼ã€ä»…ä½ç½®å‚æ•°ç­‰ã€‚

## Walrus Operator

èµ‹å€¼è¡¨è¾¾å¼ `:=` å…è®¸åœ¨è¡¨è¾¾å¼ä¸­è¿›è¡Œèµ‹å€¼æ“ä½œã€‚æ›´å¤šä¿¡æ¯è¯·è®¿é—® [å®˜æ–¹æ–‡æ¡£](https://docs.python.org)ã€‚

### ç¤ºä¾‹ä»£ç 

```python
if (n := len(data)) > 10:
    print(f"æ•°æ®é‡: {n}")
```

## æ€§èƒ½æ”¹è¿›

Python 3.8 åœ¨å¤šä¸ªæ–¹é¢è¿›è¡Œäº†æ€§èƒ½ä¼˜åŒ–ã€‚

## æ€»ç»“

æœ¬æ–‡ä»‹ç»äº† Python 3.8 çš„æ ¸å¿ƒç‰¹æ€§ï¼Œæ¨èæ‰€æœ‰å¼€å‘è€…å‡çº§ã€‚æ›´å¤šè¯¦æƒ…è¯·å‚è€ƒ [PEP 572](https://peps.python.org/pep-0572/)ã€‚
"""


# ============ æ–‡æ¡£åˆ†æå™¨ç±» ============

class MarkdownDocument:
    """Markdown æ–‡æ¡£åˆ†æå™¨
    
    ä½¿ç”¨ cached_property ç¡®ä¿æ˜‚è´µçš„è§£ææ“ä½œåªæ‰§è¡Œä¸€æ¬¡
    """
    
    def __init__(self, content: str):
        self.content = content
        print(f"ğŸ“„ åˆå§‹åŒ–æ–‡æ¡£ï¼ˆ{len(content)} å­—ç¬¦ï¼‰")
    
    @cached_property
    def lines(self) -> List[str]:
        """è§£ææ–‡æ¡£ä¸ºè¡Œï¼ˆæ¨¡æ‹Ÿè€—æ—¶æ“ä½œï¼‰"""
        print("  ğŸ”„ è§£ææ–‡æ¡£è¡Œ...")
        time.sleep(0.1)  # æ¨¡æ‹Ÿ I/O è€—æ—¶
        return self.content.strip().split('\n')
    
    @cached_property
    def metadata(self) -> Dict[str, str]:
        """æå– YAML å‰ç½®å…ƒæ•°æ®"""
        print("  ğŸ”„ æå–å…ƒæ•°æ®...")
        time.sleep(0.05)
        
        meta = {}
        in_frontmatter = False
        
        for line in self.lines:
            if line.strip() == '---':
                if not in_frontmatter:
                    in_frontmatter = True
                else:
                    break
            elif in_frontmatter and ':' in line:
                key, value = line.split(':', 1)
                meta[key.strip()] = value.strip()
        
        return meta
    
    @cached_property
    def body_text(self) -> str:
        """æå–æ­£æ–‡å†…å®¹ï¼ˆå»é™¤å…ƒæ•°æ®å’Œä»£ç å—ï¼‰"""
        print("  ğŸ”„ æå–æ­£æ–‡...")
        
        # è·³è¿‡å‰ç½®å…ƒæ•°æ®
        lines = self.lines[:]
        if lines[0].strip() == '---':
            # æ‰¾åˆ°ç¬¬äºŒä¸ª ---
            for i, line in enumerate(lines[1:], 1):
                if line.strip() == '---':
                    lines = lines[i+1:]
                    break
        
        # ç§»é™¤ä»£ç å—
        text = '\n'.join(lines)
        text = re.sub(r'```.*?```', '', text, flags=re.DOTALL)
        
        # ç§»é™¤ Markdown æ ‡è®°
        text = re.sub(r'#+\s*', '', text)  # æ ‡é¢˜
        text = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', text)  # é“¾æ¥
        text = re.sub(r'[*_`]', '', text)  # å¼ºè°ƒå’Œä»£ç 
        
        return text.strip()
    
    @cached_property
    def word_count(self) -> int:
        """è®¡ç®—å­—æ•°"""
        print("  ğŸ”„ ç»Ÿè®¡å­—æ•°...")
        # ä¸­è‹±æ–‡æ··åˆè®¡æ•°
        chinese = len(re.findall(r'[\u4e00-\u9fff]', self.body_text))
        english = len(re.findall(r'\b[a-zA-Z]+\b', self.body_text))
        return chinese + english
    
    @cached_property
    def reading_time(self) -> float:
        """ä¼°ç®—é˜…è¯»æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰"""
        print("  ğŸ”„ è®¡ç®—é˜…è¯»æ—¶é—´...")
        # å‡è®¾ä¸­æ–‡ 400 å­—/åˆ†é’Ÿï¼Œè‹±æ–‡ 200 è¯/åˆ†é’Ÿ
        return self.word_count / 300
    
    @cached_property
    def headings(self) -> List[Dict[str, str]]:
        """æå–æ‰€æœ‰æ ‡é¢˜"""
        print("  ğŸ”„ æå–æ ‡é¢˜...")
        headings = []
        
        for line in self.lines:
            match = re.match(r'^(#{1,6})\s+(.+)$', line)
            if match:
                level = len(match.group(1))
                title = match.group(2)
                headings.append({'level': level, 'title': title})
        
        return headings
    
    @cached_property
    def links(self) -> List[Dict[str, str]]:
        """æå–æ‰€æœ‰é“¾æ¥"""
        print("  ğŸ”„ æå–é“¾æ¥...")
        links = []
        
        for match in re.finditer(r'\[([^\]]+)\]\(([^\)]+)\)', self.content):
            links.append({
                'text': match.group(1),
                'url': match.group(2)
            })
        
        return links
    
    @cached_property
    def summary(self) -> str:
        """ç”Ÿæˆæ–‡æ¡£æ‘˜è¦"""
        print("  ğŸ”„ ç”Ÿæˆæ‘˜è¦...")
        time.sleep(0.1)  # æ¨¡æ‹Ÿ NLP å¤„ç†
        
        # ç®€å•çš„æ‘˜è¦ï¼šå–ç¬¬ä¸€æ®µ
        paragraphs = self.body_text.split('\n\n')
        first_para = paragraphs[0] if paragraphs else ""
        
        # æˆªæ–­åˆ° 100 å­—ç¬¦
        if len(first_para) > 100:
            return first_para[:100] + "..."
        return first_para
    
    def refresh(self):
        """æ¸…é™¤æ‰€æœ‰ç¼“å­˜ï¼ˆæ¨¡æ‹Ÿæ–‡æ¡£æ›´æ–°åçš„åˆ·æ–°ï¼‰"""
        print("  ğŸ”„ æ¸…é™¤æ‰€æœ‰ç¼“å­˜...")
        cache_keys = [
            'lines', 'metadata', 'body_text', 'word_count',
            'reading_time', 'headings', 'links', 'summary'
        ]
        for key in cache_keys:
            self.__dict__.pop(key, None)


# ============ ä½¿ç”¨æ¼”ç¤º ============

def main():
    print("=" * 60)
    print("Markdown æ–‡æ¡£åˆ†æå™¨æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºæ–‡æ¡£å¯¹è±¡
    doc = MarkdownDocument(SAMPLE_MARKDOWN)
    
    # ===== æ¼”ç¤º 1: é¦–æ¬¡è®¿é—®ä¼šè§¦å‘è®¡ç®— =====
    print("\n[æ¼”ç¤º 1] é¦–æ¬¡è®¿é—®å±æ€§")
    print("-" * 60)
    
    print(f"ğŸ“Š å…ƒæ•°æ®: {doc.metadata}")
    print(f"ğŸ“Š å­—æ•°ç»Ÿè®¡: {doc.word_count}")
    print(f"ğŸ“Š é˜…è¯»æ—¶é—´: {doc.reading_time:.1f} åˆ†é’Ÿ")
    
    # ===== æ¼”ç¤º 2: å†æ¬¡è®¿é—®ç›´æ¥è¿”å›ç¼“å­˜ =====
    print("\n[æ¼”ç¤º 2] å†æ¬¡è®¿é—®ï¼ˆæ³¨æ„æ— è®¡ç®—æç¤ºï¼‰")
    print("-" * 60)
    
    start = time.time()
    for _ in range(3):
        _ = doc.word_count
        _ = doc.reading_time
    elapsed = time.time() - start
    print(f"âœ… 6 æ¬¡å±æ€§è®¿é—®è€—æ—¶: {elapsed*1000:.2f} msï¼ˆå‡ ä¹æ— è€—æ—¶ï¼‰")
    
    # ===== æ¼”ç¤º 3: æŸ¥çœ‹ç¼“å­˜å†…å®¹ =====
    print("\n[æ¼”ç¤º 3] æŸ¥çœ‹å¯¹è±¡çš„ç¼“å­˜çŠ¶æ€")
    print("-" * 60)
    
    cache_keys = [k for k in doc.__dict__.keys() if not k.startswith('_')]
    print(f"å·²ç¼“å­˜çš„å±æ€§: {cache_keys}")
    
    # ===== æ¼”ç¤º 4: å…¶ä»–åˆ†æåŠŸèƒ½ =====
    print("\n[æ¼”ç¤º 4] å…¶ä»–æ–‡æ¡£åˆ†æ")
    print("-" * 60)
    
    print(f"\næ ‡é¢˜ç»“æ„:")
    for heading in doc.headings:
        indent = "  " * (heading['level'] - 1)
        print(f"{indent}- {heading['title']}")
    
    print(f"\né“¾æ¥åˆ—è¡¨:")
    for link in doc.links:
        print(f"  - {link['text']}: {link['url']}")
    
    print(f"\næ–‡æ¡£æ‘˜è¦:")
    print(f"  {doc.summary}")
    
    # ===== æ¼”ç¤º 5: æ¸…é™¤ç¼“å­˜ =====
    print("\n[æ¼”ç¤º 5] æ¸…é™¤ç¼“å­˜åé‡æ–°è®¿é—®")
    print("-" * 60)
    
    doc.refresh()
    print(f"ğŸ“Š å­—æ•°ç»Ÿè®¡ï¼ˆé‡æ–°è®¡ç®—ï¼‰: {doc.word_count}")
    
    print("\n" + "=" * 60)
    print("âœ… æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 60)
    print("\nğŸ’¡ æ€»ç»“:")
    print("  - cached_property é¿å…äº†é‡å¤çš„æ–‡ä»¶ I/O å’Œè®¡ç®—")
    print("  - é¦–æ¬¡è®¿é—®ç¨æ…¢ï¼Œåç»­è®¿é—®å‡ ä¹é›¶æˆæœ¬")
    print("  - é€‚åˆä¸å¯å˜æ•°æ®æˆ–å¯¹è±¡ç”Ÿå‘½å‘¨æœŸå†…ä¸å˜çš„å±æ€§")


if __name__ == "__main__":
    main()
