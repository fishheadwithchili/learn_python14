"""
åœºæ™¯ 7ï¼šæ•°æ®æµå¤„ç†ä¸­çš„çŠ¶æ€è¿½è¸ª

åº”ç”¨ï¼šåœ¨ç”Ÿæˆå™¨æˆ–ç®¡é“ä¸­è¿½è¸ªä¸­é—´çŠ¶æ€ï¼Œé¿å…å¤šæ¬¡è®¡ç®—
"""

import time

class DataStream:
    """æ¨¡æ‹Ÿæ•°æ®æµï¼ˆå¦‚ç½‘ç»œæ•°æ®ã€ä¼ æ„Ÿå™¨æ•°æ®ï¼‰"""
    
    def __init__(self, data):
        self.data = data
        self.index = 0
    
    def read(self, size):
        """è¯»å–æŒ‡å®šå¤§å°çš„æ•°æ®å—"""
        if self.index >= len(self.data):
            return b''
        
        chunk = self.data[self.index:self.index + size]
        self.index += size
        
        print(f"  [è¯»å–] {len(chunk)} å­—èŠ‚")
        time.sleep(0.05)  # æ¨¡æ‹Ÿ I/O å»¶è¿Ÿ
        
        return chunk

# æ¨¡æ‹ŸäºŒè¿›åˆ¶æ•°æ®æµ
binary_data = b'Hello World! This is a stream of binary data for processing.'

print("=" * 60)
print("æ•°æ®æµå¤„ç†")
print("=" * 60)

# âŒ ä¼ ç»Ÿæ–¹å¼ - éœ€è¦å¤šæ¬¡è°ƒç”¨ len()
print("\n[ä¼ ç»Ÿæ–¹å¼] é‡å¤è°ƒç”¨ len()ï¼š\n")

stream1 = DataStream(binary_data)
chunk_size = 10
chunks_old = []

chunk = stream1.read(chunk_size)
while len(chunk) > 0:
    chunks_old.append({
        'data': chunk.decode('utf-8', errors='ignore'),
        'size': len(chunk)  # åˆè®¡ç®—ä¸€æ¬¡ï¼
    })
    chunk = stream1.read(chunk_size)

for i, chunk_info in enumerate(chunks_old, 1):
    print(f"  å— {i}: {chunk_info['size']} å­—èŠ‚ - '{chunk_info['data']}'")

# âœ… ä½¿ç”¨ walrus operator - è¯»å–å’Œå¤§å°æ£€æŸ¥åˆå¹¶
print("\n[Walrus Operator] åˆå¹¶è¯»å–å’Œæ£€æŸ¥ï¼š\n")

stream2 = DataStream(binary_data)
chunks_new = []

while (chunk := stream2.read(chunk_size)) and (size := len(chunk)) > 0:
    chunks_new.append({
        'data': chunk.decode('utf-8', errors='ignore'),
        'size': size  # ç›´æ¥ä½¿ç”¨å·²è®¡ç®—çš„å€¼
    })

for i, chunk_info in enumerate(chunks_new, 1):
    print(f"  å— {i}: {chunk_info['size']} å­—èŠ‚ - '{chunk_info['data']}'")

print("\n" + "=" * 60)
print("ç”Ÿæˆå™¨ä¸­çš„åº”ç”¨")
print("=" * 60)

def process_stream(stream, chunk_size=10):
    """æµå¼å¤„ç†æ•°æ®ç”Ÿæˆå™¨"""
    while (batch := stream.read(chunk_size)) and (size := len(batch)) > 0:
        # åŒæ—¶yieldæ•°æ®å’Œå¤§å°
        yield {
            'chunk': batch,
            'size': size,
            'processed': batch.decode('utf-8', errors='ignore').upper()
        }

print("\nä½¿ç”¨ç”Ÿæˆå™¨å¤„ç†æµï¼š\n")

stream3 = DataStream(binary_data)
for i, result in enumerate(process_stream(stream3, 15), 1):
    print(f"  å¤„ç†å— {i}:")
    print(f"    åŸå§‹å¤§å°: {result['size']} å­—èŠ‚")
    print(f"    å¤„ç†ç»“æœ: {result['processed'][:30]}...")

print("\nğŸ’¡ æ€»ç»“ï¼šæµå¤„ç†ä¸­é¿å…é‡å¤è®¡ç®—ï¼Œæå‡å¤„ç†æ•ˆç‡")

